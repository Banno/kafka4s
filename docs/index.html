<html><head><title>kafka4s: Getting Started</title><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Jack Henry &amp; Associates, Inc.®" /><meta name="description" content="Functional programming with Kafka and Scala" /><meta name="og:image" content="/kafka4s/img/poster.png" /><meta name="image" property="og:image" content="/kafka4s/img/poster.png" /><meta name="og:title" content="kafka4s: Getting Started" /><meta name="title" property="og:title" content="kafka4s: Getting Started" /><meta name="og:site_name" content="kafka4s" /><meta name="og:url" content="" /><meta name="og:type" content="website" /><meta name="og:description" content="Functional programming with Kafka and Scala" /><link rel="icon" type="image/png" href="/kafka4s/img/favicon.png" /><meta name="twitter:title" content="kafka4s: Getting Started" /><meta name="twitter:image" content="/kafka4s/img/poster.png" /><meta name="twitter:description" content="Functional programming with Kafka and Scala" /><meta name="twitter:card" content="summary_large_image" /><link rel="icon" type="image/png" sizes="16x16" href="/kafka4s/img/favicon16x16.png" /><link rel="icon" type="image/png" sizes="24x24" href="/kafka4s/img/favicon24x24.png" /><link rel="icon" type="image/png" sizes="32x32" href="/kafka4s/img/favicon32x32.png" /><link rel="icon" type="image/png" sizes="48x48" href="/kafka4s/img/favicon48x48.png" /><link rel="icon" type="image/png" sizes="57x57" href="/kafka4s/img/favicon57x57.png" /><link rel="icon" type="image/png" sizes="60x60" href="/kafka4s/img/favicon60x60.png" /><link rel="icon" type="image/png" sizes="64x64" href="/kafka4s/img/favicon64x64.png" /><link rel="icon" type="image/png" sizes="70x70" href="/kafka4s/img/favicon70x70.png" /><link rel="icon" type="image/png" sizes="72x72" href="/kafka4s/img/favicon72x72.png" /><link rel="icon" type="image/png" sizes="76x76" href="/kafka4s/img/favicon76x76.png" /><link rel="icon" type="image/png" sizes="96x96" href="/kafka4s/img/favicon96x96.png" /><link rel="icon" type="image/png" sizes="114x114" href="/kafka4s/img/favicon114x114.png" /><link rel="icon" type="image/png" sizes="120x120" href="/kafka4s/img/favicon120x120.png" /><link rel="icon" type="image/png" sizes="128x128" href="/kafka4s/img/favicon128x128.png" /><link rel="icon" type="image/png" sizes="144x144" href="/kafka4s/img/favicon144x144.png" /><link rel="icon" type="image/png" sizes="150x150" href="/kafka4s/img/favicon150x150.png" /><link rel="icon" type="image/png" sizes="152x152" href="/kafka4s/img/favicon152x152.png" /><link rel="icon" type="image/png" sizes="196x196" href="/kafka4s/img/favicon196x196.png" /><link rel="icon" type="image/png" sizes="310x310" href="/kafka4s/img/favicon310x310.png" /><link rel="icon" type="image/png" sizes="310x150" href="/kafka4s/img/favicon310x150.png" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" /><link rel="stylesheet" href="/kafka4s/highlight/styles/atom-one-light.css" /><link rel="stylesheet" href="/kafka4s/css/style.css" /><link rel="stylesheet" href="/kafka4s/css/palette.css" /><link rel="stylesheet" href="/kafka4s/css/codemirror.css" /></head><body class="docs"><div id="wrapper"><div id="sidebar-wrapper"><ul id="sidebar" class="sidebar-nav"><li class="sidebar-brand"><a href="/kafka4s/" class="brand"><div class="brand-wrapper"><span>kafka4s</span></div></a></li> <li><a href="/kafka4s/docs/index.html" class=" active ">Getting Started</a></li> <li><a href="/kafka4s/docs/kafka-producers.html" class="">Kafka Producers</a></li> <li><a href="/kafka4s/docs/kafka-consumers.html" class="">Kafka Consumers</a></li> <li><a href="/kafka4s/docs/schema-registry.html" class="">Schema Registry Utils</a></li> <li><a href="/kafka4s/docs/kafka-client-metrics.html" class="">Kafka Client Metrics</a></li></ul></div><div id="page-content-wrapper"><div class="nav"><div class="container-fluid"><div class="row"><div class="col-lg-12"><div class="action-menu pull-left clearfix"><a href="#menu-toggle" id="menu-toggle"><i class="fa fa-bars" aria-hidden="true"></i></a></div><ul class="pull-right"><li id="gh-eyes-item" class="hidden-xs"><a href="https://github.com/Banno/kafka4s"><i class="fa fa-eye"></i><span>WATCH<span id="eyes" class="label label-default">--</span></span></a></li><li id="gh-stars-item" class="hidden-xs"><a href="https://github.com/Banno/kafka4s"><i class="fa fa-star-o"></i><span>STARS<span id="stars" class="label label-default">--</span></span></a></li><li><a href="#" onclick="shareSiteTwitter('kafka4s Functional programming with Kafka and Scala');"><i class="fa fa-twitter"></i></a></li><li><a href="#" onclick="shareSiteFacebook('kafka4s Functional programming with Kafka and Scala');"><i class="fa fa-facebook"></i></a></li><li><a href="#" onclick="shareSiteGoogle();"><i class="fa fa-google-plus"></i></a></li></ul></div></div></div></div><div id="content" data-github-owner="Banno" data-github-repo="kafka4s"><div class="content-wrapper"><section><h1 id="getting-dependency">Getting dependency</h1>

<p>To use kafka4s in an existing SBT project with Scala 2.12 or a later version, add the following dependencies to your
<code class="highlighter-rouge">build.sbt</code> depending on your needs:</p>

<div class="language-scala highlighter-rouge"><pre class="highlight"><code><span class="n">libraryDependencies</span> <span class="o">++=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"com.banno"</span> <span class="o">%%</span> <span class="s">"kafka4s"</span> <span class="o">%</span> <span class="s">"&lt;version&gt;"</span>
<span class="o">)</span>
</code></pre>
</div>

<h1 id="some-quick-examples">Some quick examples</h1>

<p>First, some initial imports:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>import cats._, cats.effect._, cats.implicits._, scala.concurrent.duration._
</code></pre>
</div>

<h3 id="define-our-data">Define our data</h3>

<p>We’ll define a toy message type for data we want to store in our Kafka topic.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>case class Customer(name: String, address: String)
case class CustomerId(id: String)
</code></pre>
</div>

<h3 id="create-our-kafka-topic">Create our Kafka topic</h3>

<p>Now we’ll tell Kafka to create a topic that we’ll write our Kafka records to.</p>

<p>First, let’s bring some types and implicits into scope:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>import com.banno.kafka._, com.banno.kafka.admin._
import org.apache.kafka.clients.admin.NewTopic
</code></pre>
</div>

<p>Now we can create a topic named <code class="highlighter-rouge">customers.v1</code> with 1 partition and 3 replicas:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>val topic = new NewTopic("customers.v1", 1, 3)
val kafkaBootstrapServers = "kafka.local:9092,kafka.local:9093" // Change as needed
AdminApi.createTopicsIdempotent[IO](kafkaBootstrapServers, topic :: Nil).unsafeRunSync
</code></pre>
</div>

<h3 id="register-our-topic-schema">Register our topic schema</h3>

<p>Let’s register a schema for our topic with the schema registry!</p>

<p>First, we bring types and implicits into scope:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>import com.banno.kafka.schemaregistry._
</code></pre>
</div>
<p>Now we initialize a schema registry client:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>val schemaRegistryUri = "http://kafka.local:8081" // Change as needed
val cachedSchemasPerSubject = 1000
val schemaRegistry = SchemaRegistryApi[IO](schemaRegistryUri, cachedSchemasPerSubject).unsafeRunSync
</code></pre>
</div>

<p>We’ll use the name of the topic we created above:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>val topicName = topic.name
</code></pre>
</div>

<p>Now we can register our topic key and topic value schemas:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>(for {
  _ &lt;- schemaRegistry.registerKey[CustomerId](topicName)
  _ &lt;- schemaRegistry.registerValue[Customer](topicName)
} yield ()).unsafeRunSync
</code></pre>
</div>

<h3 id="write-our-records-to-kafka">Write our records to Kafka</h3>

<p>Now let’s create a producer and send some records to our Kafka topic!</p>

<p>We first bring our Kafka producer utils into scope:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>import com.banno.kafka.producer._
</code></pre>
</div>

<p>Now we can create our producer instance:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>val producer = ProducerApi.generic[IO](
  BootstrapServers(kafkaBootstrapServers),
  SchemaRegistryUrl(schemaRegistryUri),
  ClientId("producer-example")
).unsafeRunSync
</code></pre>
</div>

<p>And we’ll define some customer records to be written:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>import org.apache.kafka.clients.producer.ProducerRecord
val recordsToBeWritten = (1 to 10).map(a =&gt; new ProducerRecord(topicName, CustomerId(a.toString), Customer(s"name-${a}", s"address-${a}"))).toVector
</code></pre>
</div>

<p>And now we can (attempt to) write our records to Kafka:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>recordsToBeWritten.traverse_(producer.sendSync)
</code></pre>
</div>

<p>The above fails to compile, however! Our producer writes generic
<code class="highlighter-rouge">ProducerRecord</code>s, but we’d like to send typed records, to ensure that
our <code class="highlighter-rouge">CustomerId</code> key and our <code class="highlighter-rouge">Customer</code> value are compatible with our
topic. For this, we can use Kafka4s’ <code class="highlighter-rouge">avro4s</code> integration!</p>

<h4 id="writing-typed-records-with-an-avro4s-producer">Writing typed records with an Avro4s producer</h4>

<p>Turning a generic producer into a typed producer is as simple as the following:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>val avro4sProducer = producer.toAvro4s[CustomerId, Customer]
</code></pre>
</div>

<p>We can now write our typed customer records successfully!</p>

<div class="highlighter-rouge"><pre class="highlight"><code>recordsToBeWritten.traverse_(avro4sProducer.sendSync).unsafeRunSync
</code></pre>
</div>

<h3 id="read-our-records-from-kafka">Read our records from Kafka</h3>

<p>Now that we’ve stored some records in Kafka, let’s read them as an <code class="highlighter-rouge">fs2.Stream</code>!</p>

<p>We first import our Kafka consumer utilities:</p>
<div class="highlighter-rouge"><pre class="highlight"><code>import com.banno.kafka.consumer._
</code></pre>
</div>

<p>Now we can create our consumer instance.</p>

<p>We’ll create a “shifting” Avro4s consumer, which will shift its blocking calls to a dedicated <code class="highlighter-rouge">ExecutionContext</code>, to avoid blocking the main work pool’s (typically <code class="highlighter-rouge">ExecutionContext.global</code>) threads. After receiving records, work is then shifted back to the work pool. We’ll want an implicit <code class="highlighter-rouge">ContextShift</code> instance in scope to manage this thread shifting for us.</p>

<p>Here’s our <code class="highlighter-rouge">ContextShift</code>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>implicit val CS = IO.contextShift(scala.concurrent.ExecutionContext.global)
</code></pre>
</div>

<p>And here’s our consumer, along with the <code class="highlighter-rouge">ExecutionContext</code> we’ll want our consumer to use:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>val blockingContext = ExecutionContext.fromExecutorService(Executors.newFixedThreadPool(1)) 
val consumer = ConsumerApi.avro4sShifting[IO, CustomerId, Customer](
  blockingContext,
  BootstrapServers(kafkaBootstrapServers), 
  SchemaRegistryUrl(schemaRegistryUri),
  ClientId("consumer-example"),
  GroupId("consumer-example-group")
).unsafeRunSync
</code></pre>
</div>

<p>With our Kafka consumer in hand, we can now read a stream of messages from Kafka:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>val messageStream = consumer.recordStream(
  initialize = consumer.subscribe(topicName),
  pollTimeout = 1.second
)
</code></pre>
</div>

<p>And we can now run the stream to retrieve the topic’s messages:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>val messages = messageStream.take(5).compile.toVector.unsafeRunSync
</code></pre>
</div>

<p>Voila!</p>

<p>Now that we’ve seen a quick overview, we can take a look at more in-depth documentation of Kafka4s utilities.</p>
</section></div></div></div></div><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script><script src="/kafka4s/highlight/highlight.pack.js"></script><script>hljs.configure({languages:['scala','java','bash']});
hljs.initHighlighting();
              </script><script>((window.gitter = {}).chat = {}).options = {
room: 'Banno/kafka4s'};</script><script src="https://sidecar.gitter.im/dist/sidecar.v1.js"></script><script src="/kafka4s/js/main.js"></script></body></html>