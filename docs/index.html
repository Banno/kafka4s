<!DOCTYPE html><html><head><title>kafka4s: Getting Started</title><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Jack Henry &amp; Associates, Inc.®" /><meta name="description" content="Functional programming with Kafka and Scala" /><meta name="og:image" content="/kafka4s/img/poster.png" /><meta name="image" property="og:image" content="/kafka4s/img/poster.png" /><meta name="og:title" content="kafka4s: Getting Started" /><meta name="title" property="og:title" content="kafka4s: Getting Started" /><meta name="og:site_name" content="kafka4s" /><meta name="og:url" content="https://github.com/banno/kafka4s" /><meta name="og:type" content="website" /><meta name="og:description" content="Functional programming with Kafka and Scala" /><link rel="icon" type="image/png" href="/kafka4s/img/favicon.png" /><meta name="twitter:title" content="kafka4s: Getting Started" /><meta name="twitter:image" content="/kafka4s/img/poster.png" /><meta name="twitter:description" content="Functional programming with Kafka and Scala" /><meta name="twitter:card" content="summary_large_image" /><meta name="twitter:site" content="@kafka4s" /><link rel="icon" type="image/png" sizes="16x16" href="/kafka4s/img/favicon16x16.png" /><link rel="icon" type="image/png" sizes="24x24" href="/kafka4s/img/favicon24x24.png" /><link rel="icon" type="image/png" sizes="32x32" href="/kafka4s/img/favicon32x32.png" /><link rel="icon" type="image/png" sizes="48x48" href="/kafka4s/img/favicon48x48.png" /><link rel="icon" type="image/png" sizes="57x57" href="/kafka4s/img/favicon57x57.png" /><link rel="icon" type="image/png" sizes="60x60" href="/kafka4s/img/favicon60x60.png" /><link rel="icon" type="image/png" sizes="64x64" href="/kafka4s/img/favicon64x64.png" /><link rel="icon" type="image/png" sizes="70x70" href="/kafka4s/img/favicon70x70.png" /><link rel="icon" type="image/png" sizes="72x72" href="/kafka4s/img/favicon72x72.png" /><link rel="icon" type="image/png" sizes="76x76" href="/kafka4s/img/favicon76x76.png" /><link rel="icon" type="image/png" sizes="96x96" href="/kafka4s/img/favicon96x96.png" /><link rel="icon" type="image/png" sizes="114x114" href="/kafka4s/img/favicon114x114.png" /><link rel="icon" type="image/png" sizes="120x120" href="/kafka4s/img/favicon120x120.png" /><link rel="icon" type="image/png" sizes="128x128" href="/kafka4s/img/favicon128x128.png" /><link rel="icon" type="image/png" sizes="144x144" href="/kafka4s/img/favicon144x144.png" /><link rel="icon" type="image/png" sizes="150x150" href="/kafka4s/img/favicon150x150.png" /><link rel="icon" type="image/png" sizes="152x152" href="/kafka4s/img/favicon152x152.png" /><link rel="icon" type="image/png" sizes="196x196" href="/kafka4s/img/favicon196x196.png" /><link rel="icon" type="image/png" sizes="310x310" href="/kafka4s/img/favicon310x310.png" /><link rel="icon" type="image/png" sizes="310x150" href="/kafka4s/img/favicon310x150.png" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" /><link rel="stylesheet" href="/kafka4s/highlight/styles/atom-one-light.css" /><link rel="stylesheet" href="/kafka4s/css/light-style.css" /></head><body class="docs"><div id="wrapper"><div id="sidebar-wrapper"><div id="sidebar-brand"><a href="/kafka4s/" class="brand"><div class="brand-wrapper"></div><span>kafka4s</span></a><button id="main-toggle" class="sidebar-toggle"><span class="close"></span></button></div><div class="sidebar-nav"> <div class="sidebar-nav-item active "><a href="/kafka4s/docs/index.html" title="Getting Started" class="active">Getting Started</a></div> <div class="sidebar-nav-item  "><a href="/kafka4s/docs/kafka-producers.html" title="Kafka Producers" class="">Kafka Producers</a></div> <div class="sidebar-nav-item  "><a href="/kafka4s/docs/kafka-consumers.html" title="Kafka Consumers" class="">Kafka Consumers</a></div> <div class="sidebar-nav-item  "><a href="/kafka4s/docs/schema-registry.html" title="Schema Registry Utils" class="">Schema Registry Utils</a></div> <div class="sidebar-nav-item  "><a href="/kafka4s/docs/kafka-client-metrics.html" title="Kafka Client Metrics" class="">Kafka Client Metrics</a></div></div></div><div id="page-content-wrapper"><div class="nav"><div class="container-fluid"><div class="row"><div class="col-lg-12"><div class="action-menu pull-left clearfix"><a href="#menu-toggle" id="menu-toggle"><i class="fa fa-bars" aria-hidden="true"></i></a></div><ul class="pull-right"><li id="gh-eyes-item" class="hidden-xs"><a href="https://github.com/Banno/kafka4s" target="_blank" rel="noopener noreferrer"><i class="fa fa-eye"></i><span>Watchers<span id="eyes" class="label label-default">--</span></span></a></li><li id="gh-stars-item" class="hidden-xs"><a href="https://github.com/Banno/kafka4s" target="_blank" rel="noopener noreferrer"><i class="fa fa-star-o"></i><span>Stars<span id="stars" class="label label-default">--</span></span></a></li></ul></div></div></div></div><div id="content" data-github-owner="Banno" data-github-repo="kafka4s"><div class="content-wrapper"><section><h1 id="getting-dependency">Getting dependency</h1>

<p>To use kafka4s in an existing SBT project with Scala 2.12 or a later version, add the following dependencies to your
<code class="language-plaintext highlighter-rouge">build.sbt</code> depending on your needs:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">libraryDependencies</span> <span class="o">++=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"com.banno"</span> <span class="o">%%</span> <span class="s">"kafka4s"</span> <span class="o">%</span> <span class="s">"&lt;version&gt;"</span>
<span class="o">)</span>
</code></pre></div></div>

<h1 id="some-quick-examples">Some quick examples</h1>

<p>First, some initial imports:</p>
<pre><code class="language-tut">import cats._, cats.effect._, cats.implicits._, scala.concurrent.duration._
</code></pre>

<h3 id="define-our-data">Define our data</h3>

<p>We’ll define a toy message type for data we want to store in our Kafka topic.</p>

<pre><code class="language-tut">case class Customer(name: String, address: String)
case class CustomerId(id: String)
</code></pre>

<h3 id="create-our-kafka-topic">Create our Kafka topic</h3>

<p>Now we’ll tell Kafka to create a topic that we’ll write our Kafka records to.</p>

<p>First, let’s bring some types and implicits into scope:</p>

<pre><code class="language-tut">import com.banno.kafka._, com.banno.kafka.admin._
import org.apache.kafka.clients.admin.NewTopic
</code></pre>

<p>Now we can create a topic named <code class="language-plaintext highlighter-rouge">customers.v1</code> with 1 partition and 1 replica:</p>

<pre><code class="language-tut">val topic = new NewTopic("customers.v1", 1, 1.toShort)
val kafkaBootstrapServers = "localhost:9092" // Change as needed
AdminApi.createTopicsIdempotent[IO](kafkaBootstrapServers, topic :: Nil).unsafeRunSync
</code></pre>

<h3 id="register-our-topic-schema">Register our topic schema</h3>

<p>Let’s register a schema for our topic with the schema registry!</p>

<p>First, we bring types and implicits into scope:</p>

<pre><code class="language-tut">import com.banno.kafka.schemaregistry._
</code></pre>

<p>We’ll use the name of the topic we created above:</p>

<pre><code class="language-tut">val topicName = topic.name
</code></pre>

<p>Now we can register our topic key and topic value schemas:</p>

<pre><code class="language-tut">val schemaRegistryUri = "http://localhost:8081" // Change as needed

SchemaRegistryApi.register[IO, CustomerId, Customer](
  schemaRegistryUri, topicName
).unsafeRunSync()
</code></pre>

<h3 id="write-our-records-to-kafka">Write our records to Kafka</h3>

<p>Now let’s create a producer and send some records to our Kafka topic!</p>

<p>We first bring our Kafka producer utils into scope:</p>

<pre><code class="language-tut">import com.banno.kafka.producer._
</code></pre>

<p>Now we can create our producer instance:</p>

<pre><code class="language-tut">val producer = ProducerApi.Avro.Generic.resource[IO](
  BootstrapServers(kafkaBootstrapServers),
  SchemaRegistryUrl(schemaRegistryUri),
  ClientId("producer-example")
)
</code></pre>

<p>And we’ll define some customer records to be written:</p>

<pre><code class="language-tut">import org.apache.kafka.clients.producer.ProducerRecord
val recordsToBeWritten = (1 to 10).map(a =&gt; new ProducerRecord(topicName, CustomerId(a.toString), Customer(s"name-${a}", s"address-${a}"))).toVector
</code></pre>

<p>And now we can (attempt to) write our records to Kafka:</p>

<pre><code class="language-tut:fail">producer.use(p =&gt; recordsToBeWritten.traverse_(p.sendSync))
</code></pre>

<p>The above fails to compile, however! Our producer writes generic
<code class="language-plaintext highlighter-rouge">ProducerRecord</code>s, but we’d like to send typed records, to ensure that
our <code class="language-plaintext highlighter-rouge">CustomerId</code> key and our <code class="language-plaintext highlighter-rouge">Customer</code> value are compatible with our
topic. For this, we can use Kafka4s’ <code class="language-plaintext highlighter-rouge">avro4s</code> integration!</p>

<h4 id="writing-typed-records-with-an-avro4s-producer">Writing typed records with an Avro4s producer</h4>

<p>Turning a generic producer into a typed producer is simple. We first ensure that <code class="language-plaintext highlighter-rouge">com.sksamuel.avro4s.RecordFormat</code> instances for our data are in scope:</p>

<pre><code class="language-tut">implicit val CustomerRecordFormat = com.sksamuel.avro4s.RecordFormat[Customer]
implicit val CustomerIdRecordFormat = com.sksamuel.avro4s.RecordFormat[CustomerId]

</code></pre>

<p>And with those implicits in scope, we can create our producer:</p>

<pre><code class="language-tut">val avro4sProducer = producer.map(_.toAvro4s[CustomerId, Customer])
</code></pre>

<p>We can now write our typed customer records successfully!</p>

<pre><code class="language-tut">avro4sProducer.use(p =&gt; recordsToBeWritten.traverse_(r =&gt; p.sendSync(r).flatMap(rmd =&gt; IO(println(s"Wrote record to ${rmd}"))))).unsafeRunSync
</code></pre>

<h3 id="read-our-records-from-kafka">Read our records from Kafka</h3>

<p>Now that we’ve stored some records in Kafka, let’s read them as an <code class="language-plaintext highlighter-rouge">fs2.Stream</code>!</p>

<p>We first import our Kafka consumer utilities:</p>
<pre><code class="language-tut">import com.banno.kafka.consumer._
</code></pre>

<p>Now we can create our consumer instance.</p>

<p>By default, kafka4s consumers shift blocking calls to a dedicated <code class="language-plaintext highlighter-rouge">ExecutionContext</code> backed by a singleton thread pool, to avoid blocking the main work pool’s (typically <code class="language-plaintext highlighter-rouge">ExecutionContext.global</code>) threads, and as a simple synchronization mechanism because the underlying Java client <code class="language-plaintext highlighter-rouge">KafkaConsumer</code> is not thread-safe. After receiving records, work is then shifted back to the work pool. We’ll want an implicit <code class="language-plaintext highlighter-rouge">ContextShift</code> instance in scope to manage this thread shifting for us.</p>

<p>Here’s our <code class="language-plaintext highlighter-rouge">ContextShift</code>:</p>

<pre><code class="language-tut">import scala.concurrent.ExecutionContext
implicit val CS = IO.contextShift(ExecutionContext.global)
</code></pre>

<p>And here’s our consumer, which is using Avro4s to deserialize the records:</p>

<pre><code class="language-tut">val consumer = ConsumerApi.Avro4s.resource[IO, CustomerId, Customer](
  BootstrapServers(kafkaBootstrapServers), 
  SchemaRegistryUrl(schemaRegistryUri),
  ClientId("consumer-example"),
  GroupId("consumer-example-group")
)
</code></pre>

<p>With our Kafka consumer in hand, we’ll assign to our consumer our topic partition, with no offsets, so that it starts reading from the first record, and read a stream of records from our Kafka topic:</p>
<pre><code class="language-tut">import org.apache.kafka.common.TopicPartition
val initialOffsets = Map.empty[TopicPartition, Long] // Start from beginning
val messages = consumer.use(c =&gt; c.assign(topicName, initialOffsets) *&gt; c.recordStream(1.second).take(5).compile.toVector).unsafeRunSync
</code></pre>

<p>Because the producer and consumer above were created within a <code class="language-plaintext highlighter-rouge">Resource</code> context, everything was closed and shut down properly.</p>

<p>Now that we’ve seen a quick overview, we can take a look at more in-depth documentation of Kafka4s utilities.</p>
</section></div></div></div></div><script src="/kafka4s/highlight/highlight.pack.js"></script><script>
// For all code blocks, copy the language from the containing div
// to the inner code tag (where hljs expects it to be)
const langPrefix = 'language-';
document.querySelectorAll(`div[class^='${langPrefix}']`).forEach(function(div) {
  div.classList.forEach(function(cssClass) {
    if (cssClass.startsWith(langPrefix)) {
      const lang = cssClass.substring(langPrefix.length);
      div.querySelectorAll('pre code').forEach(function(code) {
        code.classList.add(lang);
      });
    }
  });
});

hljs.configure({languages:['scala','java','bash']});
hljs.initHighlightingOnLoad();
      </script><script>console.info('\x57\x65\x62\x73\x69\x74\x65\x20\x62\x75\x69\x6c\x74\x20\x77\x69\x74\x68\x3a\x0a\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x5f\x5f\x0a\x20\x20\x20\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x5f\x20\x20\x2f\x20\x2f\x5f\x20\x20\x20\x20\x20\x20\x5f\x5f\x5f\x5f\x20\x5f\x5f\x5f\x20\x20\x28\x5f\x29\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x28\x5f\x29\x20\x2f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x0a\x20\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x60\x5f\x5f\x20\x5c\x2f\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x20\x2f\x20\x5f\x5f\x2f\x20\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x0a\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x5f\x2f\x20\x2f\x20\x2f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x5f\x5f\x2f\x20\x2f\x20\x20\x2f\x20\x2f\x5f\x2f\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x20\x2f\x5f\x2f\x20\x20\x5f\x5f\x28\x5f\x5f\x20\x20\x29\x0a\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2e\x5f\x5f\x5f\x2f\x5c\x5f\x5f\x2f\x20\x20\x20\x20\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x2f\x20\x20\x20\x5c\x5f\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x0a\x0a\x68\x74\x74\x70\x73\x3a\x2f\x2f\x34\x37\x64\x65\x67\x2e\x67\x69\x74\x68\x75\x62\x2e\x69\x6f\x2f\x73\x62\x74\x2d\x6d\x69\x63\x72\x6f\x73\x69\x74\x65\x73')</script><script>((window.gitter = {}).chat = {}).options = {
room: 'Banno/kafka4s'};</script><script src="https://sidecar.gitter.im/dist/sidecar.v1.js"></script><script src="/kafka4s/js/docs.js"></script></body></html>