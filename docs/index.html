<!DOCTYPE html><html><head><title>kafka4s: Getting Started</title><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Jack Henry &amp; Associates, Inc.®" /><meta name="description" content="Functional programming with Kafka and Scala" /><meta name="og:image" content="/kafka4s/img/poster.png" /><meta name="image" property="og:image" content="/kafka4s/img/poster.png" /><meta name="og:title" content="kafka4s: Getting Started" /><meta name="title" property="og:title" content="kafka4s: Getting Started" /><meta name="og:site_name" content="kafka4s" /><meta name="og:url" content="https://github.com/banno/kafka4s" /><meta name="og:type" content="website" /><meta name="og:description" content="Functional programming with Kafka and Scala" /><link rel="icon" type="image/png" href="/kafka4s/img/favicon.png" /><meta name="twitter:title" content="kafka4s: Getting Started" /><meta name="twitter:image" content="/kafka4s/img/poster.png" /><meta name="twitter:description" content="Functional programming with Kafka and Scala" /><meta name="twitter:card" content="summary_large_image" /><meta name="twitter:site" content="@kafka4s" /><link rel="icon" type="image/png" sizes="16x16" href="/kafka4s/img/favicon16x16.png" /><link rel="icon" type="image/png" sizes="24x24" href="/kafka4s/img/favicon24x24.png" /><link rel="icon" type="image/png" sizes="32x32" href="/kafka4s/img/favicon32x32.png" /><link rel="icon" type="image/png" sizes="48x48" href="/kafka4s/img/favicon48x48.png" /><link rel="icon" type="image/png" sizes="57x57" href="/kafka4s/img/favicon57x57.png" /><link rel="icon" type="image/png" sizes="60x60" href="/kafka4s/img/favicon60x60.png" /><link rel="icon" type="image/png" sizes="64x64" href="/kafka4s/img/favicon64x64.png" /><link rel="icon" type="image/png" sizes="70x70" href="/kafka4s/img/favicon70x70.png" /><link rel="icon" type="image/png" sizes="72x72" href="/kafka4s/img/favicon72x72.png" /><link rel="icon" type="image/png" sizes="76x76" href="/kafka4s/img/favicon76x76.png" /><link rel="icon" type="image/png" sizes="96x96" href="/kafka4s/img/favicon96x96.png" /><link rel="icon" type="image/png" sizes="114x114" href="/kafka4s/img/favicon114x114.png" /><link rel="icon" type="image/png" sizes="120x120" href="/kafka4s/img/favicon120x120.png" /><link rel="icon" type="image/png" sizes="128x128" href="/kafka4s/img/favicon128x128.png" /><link rel="icon" type="image/png" sizes="144x144" href="/kafka4s/img/favicon144x144.png" /><link rel="icon" type="image/png" sizes="150x150" href="/kafka4s/img/favicon150x150.png" /><link rel="icon" type="image/png" sizes="152x152" href="/kafka4s/img/favicon152x152.png" /><link rel="icon" type="image/png" sizes="196x196" href="/kafka4s/img/favicon196x196.png" /><link rel="icon" type="image/png" sizes="310x310" href="/kafka4s/img/favicon310x310.png" /><link rel="icon" type="image/png" sizes="310x150" href="/kafka4s/img/favicon310x150.png" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" /><link rel="stylesheet" href="/kafka4s/highlight/styles/atom-one-light.css" /><link rel="stylesheet" href="/kafka4s/css/light-style.css" /></head><body class="docs"><div id="wrapper"><div id="sidebar-wrapper"><div id="sidebar-brand"><a href="/kafka4s/" class="brand"><div class="brand-wrapper"></div><span>kafka4s</span></a><button id="main-toggle" class="sidebar-toggle"><span class="close"></span></button></div><div class="sidebar-nav"> <div class="sidebar-nav-item active "><a href="/kafka4s/docs/index.html" title="Getting Started" class="active">Getting Started</a></div> <div class="sidebar-nav-item  "><a href="/kafka4s/docs/kafka-producers.html" title="Kafka Producers" class="">Kafka Producers</a></div> <div class="sidebar-nav-item  "><a href="/kafka4s/docs/kafka-consumers.html" title="Kafka Consumers" class="">Kafka Consumers</a></div> <div class="sidebar-nav-item  "><a href="/kafka4s/docs/schema-registry.html" title="Schema Registry Utils" class="">Schema Registry Utils</a></div> <div class="sidebar-nav-item  "><a href="/kafka4s/docs/kafka-client-metrics.html" title="Kafka Client Metrics" class="">Kafka Client Metrics</a></div></div></div><div id="page-content-wrapper"><div class="nav"><div class="container-fluid"><div class="row"><div class="col-lg-12"><div class="action-menu pull-left clearfix"><a href="#menu-toggle" id="menu-toggle"><i class="fa fa-bars" aria-hidden="true"></i></a></div><ul class="pull-right"><li class="search-nav"><div id="search-dropdown"><label><i class="fa fa-search"></i>Search</label><input id="search-bar" type="text" placeholder="Enter keywords here..." onclick="displayToggleSearch(event)" /><ul id="search-dropdown-content" class="dropdown dropdown-content"></ul></div></li><li id="gh-eyes-item" class="hidden-xs to-uppercase"><a href="https://github.com/Banno/kafka4s" target="_blank" rel="noopener noreferrer"><i class="fa fa-eye"></i><span>Watchers<span id="eyes" class="label label-default">--</span></span></a></li><li id="gh-stars-item" class="hidden-xs to-uppercase"><a href="https://github.com/Banno/kafka4s" target="_blank" rel="noopener noreferrer"><i class="fa fa-star-o"></i><span>Stars<span id="stars" class="label label-default">--</span></span></a></li></ul></div></div></div></div><div id="content" data-github-owner="Banno" data-github-repo="kafka4s"><div class="content-wrapper"><section><h1 id="getting-dependency">Getting dependency</h1>

<p>To use kafka4s in an existing SBT project with Scala 2.13 or a later version, add the following dependencies to your
<code class="language-plaintext highlighter-rouge">build.sbt</code> depending on your needs:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">libraryDependencies</span> <span class="o">++=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"com.banno"</span> <span class="o">%%</span> <span class="s">"kafka4s"</span> <span class="o">%</span> <span class="s">"&lt;version&gt;"</span>
<span class="o">)</span>
</code></pre></div></div>

<h1 id="some-quick-examples">Some quick examples</h1>

<p>First, some initial imports:</p>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">cats._</span><span class="o">,</span> <span class="nv">cats</span><span class="o">.</span><span class="py">effect</span><span class="o">.</span><span class="py">_</span><span class="o">,</span> <span class="nv">cats</span><span class="o">.</span><span class="py">implicits</span><span class="o">.</span><span class="py">_</span><span class="o">,</span> <span class="nv">scala</span><span class="o">.</span><span class="py">concurrent</span><span class="o">.</span><span class="py">duration</span><span class="o">.</span><span class="py">_</span>
</code></pre></div></div>

<h3 id="define-our-data">Define our data</h3>

<p>We’ll define a toy message type for data we want to store in our Kafka topic.</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">case</span> <span class="k">class</span> <span class="nc">Customer</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">address</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">CustomerId</span><span class="o">(</span><span class="n">id</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span>
</code></pre></div></div>

<h3 id="create-our-kafka-topic">Create our Kafka topic</h3>

<p>Now we’ll tell Kafka to create a topic that we’ll write our Kafka records to.</p>

<p>First, let’s bring some types and implicits into scope:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.banno.kafka._</span><span class="o">,</span> <span class="nv">com</span><span class="o">.</span><span class="py">banno</span><span class="o">.</span><span class="py">kafka</span><span class="o">.</span><span class="py">admin</span><span class="o">.</span><span class="py">_</span>
<span class="k">import</span> <span class="nn">org.apache.kafka.clients.admin.NewTopic</span>
</code></pre></div></div>

<p>Now we can create a topic named <code class="language-plaintext highlighter-rouge">customers.v1</code> with 1 partition and 1 replica:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">topic</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NewTopic</span><span class="o">(</span><span class="s">"customers.v1"</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mf">1.</span><span class="n">toShort</span><span class="o">)</span>
<span class="c1">// topic: NewTopic = (name=customers.v1, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs=null)</span>
<span class="k">val</span> <span class="nv">kafkaBootstrapServers</span> <span class="k">=</span> <span class="s">"localhost:9092"</span> <span class="c1">// Change as needed</span>
<span class="c1">// kafkaBootstrapServers: String = "localhost:9092"</span>
</code></pre></div></div>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">cats.effect.unsafe.implicits.global</span>
<span class="nv">AdminApi</span><span class="o">.</span><span class="py">createTopicsIdempotent</span><span class="o">[</span><span class="kt">IO</span><span class="o">](</span><span class="n">kafkaBootstrapServers</span><span class="o">,</span> <span class="n">topic</span> <span class="o">::</span> <span class="nc">Nil</span><span class="o">).</span><span class="py">unsafeRunSync</span><span class="o">()</span>
</code></pre></div></div>

<h3 id="register-our-topic-schema">Register our topic schema</h3>

<p>Let’s register a schema for our topic with the schema registry!</p>

<p>First, we bring types and implicits into scope:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.banno.kafka.schemaregistry._</span>
</code></pre></div></div>

<p>We’ll use the name of the topic we created above:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">topicName</span> <span class="k">=</span> <span class="nv">topic</span><span class="o">.</span><span class="py">name</span>
<span class="c1">// topicName: String = "customers.v1"</span>
</code></pre></div></div>

<p>Now we can register our topic key and topic value schemas:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">schemaRegistryUri</span> <span class="k">=</span> <span class="s">"http://localhost:8091"</span> <span class="c1">// Change as needed</span>
<span class="c1">// schemaRegistryUri: String = "http://localhost:8091"</span>
</code></pre></div></div>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">cats.effect.unsafe.implicits.global</span>
<span class="nv">SchemaRegistryApi</span><span class="o">.</span><span class="py">register</span><span class="o">[</span><span class="kt">IO</span>, <span class="kt">CustomerId</span>, <span class="kt">Customer</span><span class="o">](</span>
  <span class="n">schemaRegistryUri</span><span class="o">,</span> <span class="n">topicName</span>
<span class="o">).</span><span class="py">unsafeRunSync</span><span class="o">()</span>
</code></pre></div></div>

<h3 id="write-our-records-to-kafka">Write our records to Kafka</h3>

<p>Now let’s create a producer and send some records to our Kafka topic!</p>

<p>We first bring our Kafka producer utils into scope:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.banno.kafka.producer._</span>
</code></pre></div></div>

<p>Now we can create our producer instance:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">producer</span> <span class="k">=</span> <span class="nv">ProducerApi</span><span class="o">.</span><span class="py">Avro</span><span class="o">.</span><span class="py">Generic</span><span class="o">.</span><span class="py">resource</span><span class="o">[</span><span class="kt">IO</span><span class="o">](</span>
  <span class="nc">BootstrapServers</span><span class="o">(</span><span class="n">kafkaBootstrapServers</span><span class="o">),</span>
  <span class="nc">SchemaRegistryUrl</span><span class="o">(</span><span class="n">schemaRegistryUri</span><span class="o">),</span>
  <span class="nc">ClientId</span><span class="o">(</span><span class="s">"producer-example"</span><span class="o">)</span>
<span class="o">)</span>
<span class="c1">// producer: Resource[IO, ProducerApi[IO, org.apache.avro.generic.GenericRecord, org.apache.avro.generic.GenericRecord]] = Allocate(</span>
<span class="c1">//   resource = cats.effect.kernel.Resource$$$Lambda$7256/1558104445@3cfcb23c</span>
<span class="c1">// )</span>
</code></pre></div></div>

<p>And we’ll define some customer records to be written:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.kafka.clients.producer.ProducerRecord</span>
<span class="k">val</span> <span class="nv">recordsToBeWritten</span> <span class="k">=</span> <span class="o">(</span><span class="mi">1</span> <span class="n">to</span> <span class="mi">10</span><span class="o">).</span><span class="py">map</span><span class="o">(</span><span class="n">a</span> <span class="k">=&gt;</span> <span class="k">new</span> <span class="nc">ProducerRecord</span><span class="o">(</span><span class="n">topicName</span><span class="o">,</span> <span class="nc">CustomerId</span><span class="o">(</span><span class="nv">a</span><span class="o">.</span><span class="py">toString</span><span class="o">),</span> <span class="nc">Customer</span><span class="o">(</span><span class="n">s</span><span class="s">"name-${a}"</span><span class="o">,</span> <span class="n">s</span><span class="s">"address-${a}"</span><span class="o">))).</span><span class="py">toVector</span>
<span class="c1">// recordsToBeWritten: Vector[ProducerRecord[CustomerId, Customer]] = Vector(</span>
<span class="c1">//   ProducerRecord(topic=customers.v1, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=CustomerId(1), value=Customer(name-1,address-1), timestamp=null),</span>
<span class="c1">//   ProducerRecord(topic=customers.v1, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=CustomerId(2), value=Customer(name-2,address-2), timestamp=null),</span>
<span class="c1">//   ProducerRecord(topic=customers.v1, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=CustomerId(3), value=Customer(name-3,address-3), timestamp=null),</span>
<span class="c1">//   ProducerRecord(topic=customers.v1, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=CustomerId(4), value=Customer(name-4,address-4), timestamp=null),</span>
<span class="c1">//   ProducerRecord(topic=customers.v1, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=CustomerId(5), value=Customer(name-5,address-5), timestamp=null),</span>
<span class="c1">//   ProducerRecord(topic=customers.v1, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=CustomerId(6), value=Customer(name-6,address-6), timestamp=null),</span>
<span class="c1">//   ProducerRecord(topic=customers.v1, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=CustomerId(7), value=Customer(name-7,address-7), timestamp=null),</span>
<span class="c1">//   ProducerRecord(topic=customers.v1, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=CustomerId(8), value=Customer(name-8,address-8), timestamp=null),</span>
<span class="c1">//   ProducerRecord(topic=customers.v1, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=CustomerId(9), value=Customer(name-9,address-9), timestamp=null),</span>
<span class="c1">//   ProducerRecord(topic=customers.v1, partition=null, headers=RecordHeaders(headers = [], isReadOnly = false), key=CustomerId(10), value=Customer(name-10,address-10), timestamp=null)</span>
<span class="c1">// )</span>
</code></pre></div></div>

<p>And now we can (attempt to) write our records to Kafka:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">producer</span><span class="o">.</span><span class="py">use</span><span class="o">(</span><span class="n">p</span> <span class="k">=&gt;</span> <span class="nv">recordsToBeWritten</span><span class="o">.</span><span class="py">traverse_</span><span class="o">(</span><span class="nv">p</span><span class="o">.</span><span class="py">sendSync</span><span class="o">))</span>
<span class="c1">// error: type mismatch;</span>
<span class="c1">//   org.apache.kafka.clients.producer.ProducerRecord[org.apache.avro.generic.GenericRecord|repl.MdocSession.App.CustomerId, org.apache.avro.generic.GenericRecord|repl.MdocSession.App.Customer] =&gt; cats.effect.IO[org.apache.kafka.clients.producer.RecordMetadata]</span>
<span class="c1">// producer.use(p =&gt; recordsToBeWritten.traverse_(p.sendSync))</span>
<span class="c1">//                                                ^^^^^^^^^^</span>
</code></pre></div></div>

<p>The above fails to compile, however! Our producer writes generic
<code class="language-plaintext highlighter-rouge">ProducerRecord</code>s, but we’d like to send typed records, to ensure that
our <code class="language-plaintext highlighter-rouge">CustomerId</code> key and our <code class="language-plaintext highlighter-rouge">Customer</code> value are compatible with our
topic. For this, we can use Kafka4s’ <code class="language-plaintext highlighter-rouge">avro4s</code> integration!</p>

<h4 id="writing-typed-records-with-an-avro4s-producer">Writing typed records with an Avro4s producer</h4>

<p>Turning a generic producer into a typed producer is simple. We first ensure that <code class="language-plaintext highlighter-rouge">com.sksamuel.avro4s.RecordFormat</code> instances for our data are in scope:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">implicit</span> <span class="k">val</span> <span class="nv">CustomerRecordFormat</span> <span class="k">=</span> <span class="nv">com</span><span class="o">.</span><span class="py">sksamuel</span><span class="o">.</span><span class="py">avro4s</span><span class="o">.</span><span class="py">RecordFormat</span><span class="o">[</span><span class="kt">Customer</span><span class="o">]</span>
<span class="c1">// CustomerRecordFormat: com.sksamuel.avro4s.RecordFormat[Customer] = com.sksamuel.avro4s.RecordFormat$$anon$1@7627962e</span>
<span class="k">implicit</span> <span class="k">val</span> <span class="nv">CustomerIdRecordFormat</span> <span class="k">=</span> <span class="nv">com</span><span class="o">.</span><span class="py">sksamuel</span><span class="o">.</span><span class="py">avro4s</span><span class="o">.</span><span class="py">RecordFormat</span><span class="o">[</span><span class="kt">CustomerId</span><span class="o">]</span>
<span class="c1">// CustomerIdRecordFormat: com.sksamuel.avro4s.RecordFormat[CustomerId] = com.sksamuel.avro4s.RecordFormat$$anon$1@26eedc9a</span>
</code></pre></div></div>

<p>And with those implicits in scope, we can create our producer:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">avro4sProducer</span> <span class="k">=</span> <span class="nv">producer</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="nv">_</span><span class="o">.</span><span class="py">toAvro4s</span><span class="o">[</span><span class="kt">CustomerId</span>, <span class="kt">Customer</span><span class="o">])</span>
<span class="c1">// avro4sProducer: Resource[IO, ProducerApi[IO[A], CustomerId, Customer]] = Bind(</span>
<span class="c1">//   source = Allocate(</span>
<span class="c1">//     resource = cats.effect.kernel.Resource$$$Lambda$7256/1558104445@3cfcb23c</span>
<span class="c1">//   ),</span>
<span class="c1">//   fs = cats.effect.kernel.Resource$$Lambda$7343/607670105@2231eae</span>
<span class="c1">// )</span>
</code></pre></div></div>

<p>We can now write our typed customer records successfully!</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">cats.effect.unsafe.implicits.global</span>
<span class="nv">avro4sProducer</span><span class="o">.</span><span class="py">use</span><span class="o">(</span><span class="n">p</span> <span class="k">=&gt;</span>
  <span class="nv">recordsToBeWritten</span><span class="o">.</span><span class="py">traverse_</span><span class="o">(</span><span class="n">r</span> <span class="k">=&gt;</span> <span class="nv">p</span><span class="o">.</span><span class="py">sendSync</span><span class="o">(</span><span class="n">r</span><span class="o">).</span><span class="py">flatMap</span><span class="o">(</span><span class="n">rmd</span> <span class="k">=&gt;</span> <span class="nc">IO</span><span class="o">(</span><span class="nf">println</span><span class="o">(</span><span class="n">s</span><span class="s">"Wrote record to ${rmd}"</span><span class="o">))))</span>
<span class="o">).</span><span class="py">unsafeRunSync</span><span class="o">()</span>
</code></pre></div></div>

<h3 id="read-our-records-from-kafka">Read our records from Kafka</h3>

<p>Now that we’ve stored some records in Kafka, let’s read them as an <code class="language-plaintext highlighter-rouge">fs2.Stream</code>!</p>

<p>We first import our Kafka consumer utilities:</p>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.banno.kafka.consumer._</span>
</code></pre></div></div>

<p>Now we can create our consumer instance.</p>

<p>By default, <code class="language-plaintext highlighter-rouge">kafka4s</code> consumers shift blocking calls to a dedicated
<code class="language-plaintext highlighter-rouge">ExecutionContext</code> backed by a singleton thread pool, to avoid blocking the main
work pool’s (typically <code class="language-plaintext highlighter-rouge">ExecutionContext.global</code>) threads, and as a simple
synchronization mechanism because the underlying Java client <code class="language-plaintext highlighter-rouge">KafkaConsumer</code> is
not thread-safe. After receiving records, work is then shifted back to the work
pool.</p>

<p>And here’s our consumer, which is using Avro4s to deserialize the records:</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">consumer</span> <span class="k">=</span> <span class="nv">ConsumerApi</span><span class="o">.</span><span class="py">Avro4s</span><span class="o">.</span><span class="py">resource</span><span class="o">[</span><span class="kt">IO</span>, <span class="kt">CustomerId</span>, <span class="kt">Customer</span><span class="o">](</span>
  <span class="nc">BootstrapServers</span><span class="o">(</span><span class="n">kafkaBootstrapServers</span><span class="o">),</span>
  <span class="nc">SchemaRegistryUrl</span><span class="o">(</span><span class="n">schemaRegistryUri</span><span class="o">),</span>
  <span class="nc">ClientId</span><span class="o">(</span><span class="s">"consumer-example"</span><span class="o">),</span>
  <span class="nc">GroupId</span><span class="o">(</span><span class="s">"consumer-example-group"</span><span class="o">)</span>
<span class="o">)</span>
<span class="c1">// consumer: Resource[IO, ConsumerApi[IO, CustomerId, Customer]] = Bind(</span>
<span class="c1">//   source = Bind(</span>
<span class="c1">//     source = Allocate(</span>
<span class="c1">//       resource = cats.effect.kernel.Resource$$$Lambda$7256/1558104445@52f9087c</span>
<span class="c1">//     ),</span>
<span class="c1">//     fs = com.banno.kafka.consumer.ConsumerApi$Avro$$$Lambda$7346/239290386@58795073</span>
<span class="c1">//   ),</span>
<span class="c1">//   fs = cats.effect.kernel.Resource$$Lambda$7343/607670105@6b0ea0ba</span>
<span class="c1">// )</span>
</code></pre></div></div>

<p>With our Kafka consumer in hand, we’ll assign to our consumer our topic partition, with no offsets, so that it starts reading from the first record, and read a stream of records from our Kafka topic:</p>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.kafka.common.TopicPartition</span>
<span class="k">val</span> <span class="nv">initialOffsets</span> <span class="k">=</span> <span class="nv">Map</span><span class="o">.</span><span class="py">empty</span><span class="o">[</span><span class="kt">TopicPartition</span>, <span class="kt">Long</span><span class="o">]</span> <span class="c1">// Start from beginning</span>
<span class="c1">// initialOffsets: Map[TopicPartition, Long] = Map()</span>
</code></pre></div></div>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">cats.effect.unsafe.implicits.global</span>
<span class="k">val</span> <span class="nv">messages</span> <span class="k">=</span> <span class="nv">consumer</span><span class="o">.</span><span class="py">use</span><span class="o">(</span><span class="n">c</span> <span class="k">=&gt;</span>
  <span class="nv">c</span><span class="o">.</span><span class="py">assign</span><span class="o">(</span><span class="n">topicName</span><span class="o">,</span> <span class="n">initialOffsets</span><span class="o">)</span> <span class="o">*&gt;</span> <span class="nv">c</span><span class="o">.</span><span class="py">recordStream</span><span class="o">(</span><span class="mf">1.</span><span class="n">second</span><span class="o">).</span><span class="py">take</span><span class="o">(</span><span class="mi">5</span><span class="o">).</span><span class="py">compile</span><span class="o">.</span><span class="py">toVector</span>
<span class="o">).</span><span class="py">unsafeRunSync</span><span class="o">()</span>
</code></pre></div></div>

<p>Because the producer and consumer above were created within a <code class="language-plaintext highlighter-rouge">Resource</code> context, everything was closed and shut down properly.</p>

<p>Now that we’ve seen a quick overview, we can take a look at more in-depth documentation of Kafka4s utilities.</p>
</section></div></div></div></div><script src="/kafka4s/highlight/highlight.pack.js"></script><script src="/kafka4s/lunr/lunr.js"></script><script>
// For all code blocks, copy the language from the containing div
// to the inner code tag (where hljs expects it to be)
const langPrefix = 'language-';
document.querySelectorAll(`div[class^='${langPrefix}']`).forEach(function(div) {
  div.classList.forEach(function(cssClass) {
    if (cssClass.startsWith(langPrefix)) {
      const lang = cssClass.substring(langPrefix.length);
      div.querySelectorAll('pre code').forEach(function(code) {
        code.classList.add(lang);
      });
    }
  });
});

hljs.configure({languages:['scala','java','bash']});
hljs.initHighlightingOnLoad();
      </script><script>console.info('\x57\x65\x62\x73\x69\x74\x65\x20\x62\x75\x69\x6c\x74\x20\x77\x69\x74\x68\x3a\x0a\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x5f\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x20\x5f\x20\x5f\x5f\x0a\x20\x20\x20\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x5f\x20\x20\x2f\x20\x2f\x5f\x20\x20\x20\x20\x20\x20\x5f\x5f\x5f\x5f\x20\x5f\x5f\x5f\x20\x20\x28\x5f\x29\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x28\x5f\x29\x20\x2f\x5f\x5f\x5f\x5f\x20\x20\x5f\x5f\x5f\x5f\x5f\x0a\x20\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x60\x5f\x5f\x20\x5c\x2f\x20\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x5f\x2f\x20\x5f\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x20\x2f\x20\x5f\x5f\x2f\x20\x5f\x20\x5c\x2f\x20\x5f\x5f\x5f\x2f\x0a\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x5f\x2f\x20\x2f\x20\x2f\x5f\x2f\x5f\x5f\x5f\x5f\x5f\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x20\x2f\x5f\x5f\x2f\x20\x2f\x20\x20\x2f\x20\x2f\x5f\x2f\x20\x28\x5f\x5f\x20\x20\x29\x20\x2f\x20\x2f\x5f\x2f\x20\x20\x5f\x5f\x28\x5f\x5f\x20\x20\x29\x0a\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2e\x5f\x5f\x5f\x2f\x5c\x5f\x5f\x2f\x20\x20\x20\x20\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x20\x2f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x2f\x20\x20\x20\x5c\x5f\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x5f\x2f\x5c\x5f\x5f\x2f\x5c\x5f\x5f\x5f\x2f\x5f\x5f\x5f\x5f\x2f\x0a\x0a\x68\x74\x74\x70\x73\x3a\x2f\x2f\x34\x37\x64\x65\x67\x2e\x67\x69\x74\x68\x75\x62\x2e\x69\x6f\x2f\x73\x62\x74\x2d\x6d\x69\x63\x72\x6f\x73\x69\x74\x65\x73')</script><script>((window.gitter = {}).chat = {}).options = {
room: 'Banno/kafka4s'};</script><script src="https://sidecar.gitter.im/dist/sidecar.v1.js"></script><script src="/kafka4s/js/search.js"></script><script src="/kafka4s/js/docs.js"></script></body></html>